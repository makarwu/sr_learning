{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f93197be-a1e4-45ca-bf8d-427ce4f1d17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: thop in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (0.1.1.post2209072238)\n",
      "Requirement already satisfied: torch in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from thop) (2.2.2)\n",
      "Requirement already satisfied: filelock in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from torch->thop) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from torch->thop) (4.8.0)\n",
      "Requirement already satisfied: sympy in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from torch->thop) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from torch->thop) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from torch->thop) (3.1.3)\n",
      "Requirement already satisfied: fsspec in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from torch->thop) (2024.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from jinja2->torch->thop) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages (from sympy->torch->thop) (1.3.0)\n",
      "\u001b[33mWARNING: Error parsing requirements for jupyter: [Errno 2] No such file or directory: '/Users/makarwuckert/opt/anaconda3/lib/python3.9/site-packages/jupyter-1.0.0.dist-info/METADATA'\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install thop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eb1875e8-ee3e-4bc6-b4aa-68df249bdf2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "thop version: 0.1.1-2209072238\n",
      "torch version: 2.2.2\n"
     ]
    }
   ],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "import matplotlib\n",
    "import torch\n",
    "\n",
    "print(\"thop version:\", version(\"thop\"))\n",
    "print(\"torch version:\", version(\"torch\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "640e8db7-91a4-43ba-8f57-11273754e06b",
   "metadata": {},
   "source": [
    "### FLOPS Analysis\n",
    "- Flops (Floating Point Operations Per Second) measure the computational complexity of neural network models by counting the number of floating-point operations executed\n",
    "- High FLOPs -> mor intensive computations and energy consumption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b9de64ad-9289-488c-880c-ad99ca3100cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'GPTModel' from 'previous_chapters' (/Users/makarwuckert/Desktop/sr_llms/chapter4/previous_chapters.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthop\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m profile\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mprevious_chapters\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GPTModel\n\u001b[1;32m      6\u001b[0m BASE_CONFIG \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvocab_size\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m50257\u001b[39m,     \u001b[38;5;66;03m# Vocabulary size\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontext_length\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1024\u001b[39m,  \u001b[38;5;66;03m# Context length\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_rate\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m0.0\u001b[39m,        \u001b[38;5;66;03m# Dropout rate\u001b[39;00m\n\u001b[1;32m     10\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqkv_bias\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28;01mTrue\u001b[39;00m         \u001b[38;5;66;03m# Query-key-value bias\u001b[39;00m\n\u001b[1;32m     11\u001b[0m }\n\u001b[1;32m     13\u001b[0m model_configs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-small (124M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m768\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m12\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m12\u001b[39m},\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-medium (355M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1024\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m24\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m16\u001b[39m},\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-large (774M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1280\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m36\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m20\u001b[39m},\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgpt-xl (1558M)\u001b[39m\u001b[38;5;124m\"\u001b[39m: {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124memb_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m1600\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_layers\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m48\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_heads\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;241m25\u001b[39m},\n\u001b[1;32m     18\u001b[0m }\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'GPTModel' from 'previous_chapters' (/Users/makarwuckert/Desktop/sr_llms/chapter4/previous_chapters.py)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from thop import profile\n",
    "from previous_chapters import GPTModel\n",
    "\n",
    "\n",
    "BASE_CONFIG = {\n",
    "    \"vocab_size\": 50257,     # Vocabulary size\n",
    "    \"context_length\": 1024,  # Context length\n",
    "    \"drop_rate\": 0.0,        # Dropout rate\n",
    "    \"qkv_bias\": True         # Query-key-value bias\n",
    "}\n",
    "\n",
    "model_configs = {\n",
    "    \"gpt-small (124M)\": {\"emb_dim\": 768, \"n_layers\": 12, \"n_heads\": 12},\n",
    "    \"gpt-medium (355M)\": {\"emb_dim\": 1024, \"n_layers\": 24, \"n_heads\": 16},\n",
    "    \"gpt-large (774M)\": {\"emb_dim\": 1280, \"n_layers\": 36, \"n_heads\": 20},\n",
    "    \"gpt-xl (1558M)\": {\"emb_dim\": 1600, \"n_layers\": 48, \"n_heads\": 25},\n",
    "}\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "input_tensor = torch.randint(0, 50257, (2, 1024)).to(device)\n",
    "\n",
    "for size in model_configs:\n",
    "    BASE_CONFIG.update(model_configs[size])\n",
    "    \n",
    "    model = GPTModel(BASE_CONFIG).bfloat16()\n",
    "    model.to(device)\n",
    "\n",
    "    # MACS = multiply-accumulate operations\n",
    "    # MACS are typically counted as two FLOPS (one multiply and one accumulate)\n",
    "    macs, params = profile(model, inputs=(input_tensor,), verbose=False)\n",
    "    flops = 2*macs\n",
    "    print(f\"{size:18}: {flops:.1e} FLOPS\")\n",
    "    \n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53493ee0-9517-4de5-b944-60c8f212a1b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
